{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Laborator 3 - POS & Syntax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali3nnn/MasterArtificialIntelligence/blob/master/AN1_SEM2_NLP_Laborator_3_POS_%26_Syntax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLTvvoe4NNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "e226f256-4163-44b7-bead-1c05e5b19388"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install wikipedia\n",
        "!pip install pandas"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/alexmac/miniconda3/lib/python3.7/site-packages (3.4.5)\n",
            "Requirement already satisfied: six in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: wikipedia in /Users/alexmac/miniconda3/lib/python3.7/site-packages (1.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from wikipedia) (2.22.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from wikipedia) (4.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2019.11.28)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from beautifulsoup4->wikipedia) (2.0)\n",
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/1e/96282ff3db30befbbf8012ea69ecb0adc5e1064ef38e912bb8a3e4cfbccf/pandas-1.0.3-cp37-cp37m-macosx_10_9_x86_64.whl (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from pandas) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/alexmac/miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Installing collected packages: pandas\n",
            "Successfully installed pandas-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYvq3lEW3PvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tag.stanford import StanfordPOSTagger\n",
        "import nltk\n",
        "import wikipedia\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lem=WordNetLemmatizer()\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import sys\n",
        "from collections import Counter\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uIcTSr8PHjC",
        "colab_type": "text"
      },
      "source": [
        "# Exercitiul 1.1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2WsNZonPHKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny = wikipedia.page(\"New York City\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25vqu1DAQTdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "68f4a490-e733-40de-ca2f-236fba8c086c"
      },
      "source": [
        "print(\"Title:\",ny.title)\n",
        "first200w = word_tokenize(ny.content)[:200]\n",
        "print(\"First 200 words:\", first200w)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: New York City\n",
            "First 200 words: ['New', 'York', 'City', '(', 'NYC', ')', ',', 'often', 'called', 'the', 'City', 'of', 'New', 'York', 'or', 'simply', 'New', 'York', '(', 'NY', ')', ',', 'is', 'the', 'most', 'populous', 'city', 'in', 'the', 'United', 'States', '.', 'With', 'an', 'estimated', '2018', 'population', 'of', '8,398,748', 'distributed', 'over', 'about', '302.6', 'square', 'miles', '(', '784', 'km2', ')', ',', 'New', 'York', 'is', 'also', 'the', 'most', 'densely', 'populated', 'major', 'city', 'in', 'the', 'United', 'States', '.', 'Located', 'at', 'the', 'southern', 'tip', 'of', 'the', 'U.S.', 'state', 'of', 'New', 'York', ',', 'the', 'city', 'is', 'the', 'center', 'of', 'the', 'New', 'York', 'metropolitan', 'area', ',', 'the', 'largest', 'metropolitan', 'area', 'in', 'the', 'world', 'by', 'urban', 'landmass', '.', 'With', 'almost', '20', 'million', 'people', 'in', 'its', 'metropolitan', 'statistical', 'area', 'and', 'approximately', '23', 'million', 'in', 'its', 'combined', 'statistical', 'area', ',', 'it', 'is', 'one', 'of', 'the', 'world', \"'s\", 'most', 'populous', 'megacities', '.', 'New', 'York', 'City', 'has', 'been', 'described', 'as', 'the', 'cultural', ',', 'financial', ',', 'and', 'media', 'capital', 'of', 'the', 'world', ',', 'significantly', 'influencing', 'commerce', ',', 'entertainment', ',', 'research', ',', 'technology', ',', 'education', ',', 'politics', ',', 'tourism', ',', 'art', ',', 'fashion', ',', 'and', 'sports', '.', 'Home', 'to', 'the', 'headquarters', 'of', 'the', 'United', 'Nations', ',', 'New', 'York', 'is', 'an', 'important', 'center', 'for', 'international', 'diplomacy.Situated', 'on', 'one', 'of', 'the', 'world', \"'s\", 'largest', 'natural']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riga4gD2QTYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first200s = sent_tokenize(ny.content)[:200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYkozdpi3PvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagger=StanfordPOSTagger('stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger', 'stanford-postagger-2018-10-16/stanford-postagger.jar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4ZAtkohQTTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "285a115c-c5c8-4036-b6c5-a3174a7e3a85"
      },
      "source": [
        "counter = 0\n",
        "pos_list = []\n",
        "for sentence in first200s[:20]:\n",
        "  counter += 1\n",
        "  pos_list.append(tagger.tag(sentence.split()))\n",
        "  print(counter, pos_list[-1])\n",
        "  print()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 [('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('(NYC),', 'NNP'), ('often', 'RB'), ('called', 'VBD'), ('the', 'DT'), ('City', 'NNP'), ('of', 'IN'), ('New', 'NNP'), ('York', 'NNP'), ('or', 'CC'), ('simply', 'RB'), ('New', 'NNP'), ('York', 'NNP'), ('(NY),', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('populous', 'JJ'), ('city', 'NN'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States.', 'NNP')]\n",
            "\n",
            "2 [('With', 'IN'), ('an', 'DT'), ('estimated', 'VBN'), ('2018', 'CD'), ('population', 'NN'), ('of', 'IN'), ('8,398,748', 'CD'), ('distributed', 'VBN'), ('over', 'RP'), ('about', 'IN'), ('302.6', 'CD'), ('square', 'JJ'), ('miles', 'NNS'), ('(784', 'FW'), ('km2),', 'FW'), ('New', 'NNP'), ('York', 'NNP'), ('is', 'VBZ'), ('also', 'RB'), ('the', 'DT'), ('most', 'RBS'), ('densely', 'RB'), ('populated', 'JJ'), ('major', 'JJ'), ('city', 'NN'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States.', 'NNP')]\n",
            "\n",
            "3 [('Located', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('southern', 'JJ'), ('tip', 'NN'), ('of', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('state', 'NN'), ('of', 'IN'), ('New', 'NNP'), ('York,', 'NNP'), ('the', 'DT'), ('city', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('center', 'NN'), ('of', 'IN'), ('the', 'DT'), ('New', 'NNP'), ('York', 'NNP'), ('metropolitan', 'JJ'), ('area,', 'NN'), ('the', 'DT'), ('largest', 'JJS'), ('metropolitan', 'JJ'), ('area', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('by', 'IN'), ('urban', 'JJ'), ('landmass.', 'NN')]\n",
            "\n",
            "4 [('With', 'IN'), ('almost', 'RB'), ('20', 'CD'), ('million', 'CD'), ('people', 'NNS'), ('in', 'IN'), ('its', 'PRP$'), ('metropolitan', 'JJ'), ('statistical', 'JJ'), ('area', 'NN'), ('and', 'CC'), ('approximately', 'RB'), ('23', 'CD'), ('million', 'CD'), ('in', 'IN'), ('its', 'PRP$'), ('combined', 'JJ'), ('statistical', 'JJ'), ('area,', 'NN'), ('it', 'PRP'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), (\"world's\", 'NNS'), ('most', 'RBS'), ('populous', 'JJ'), ('megacities.', 'NN')]\n",
            "\n",
            "5 [('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('described', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('cultural,', 'NN'), ('financial,', 'NN'), ('and', 'CC'), ('media', 'NNS'), ('capital', 'NN'), ('of', 'IN'), ('the', 'DT'), ('world,', 'NN'), ('significantly', 'RB'), ('influencing', 'VBG'), ('commerce,', 'FW'), ('entertainment,', 'FW'), ('research,', 'FW'), ('technology,', 'FW'), ('education,', 'FW'), ('politics,', 'FW'), ('tourism,', 'FW'), ('art,', 'FW'), ('fashion,', 'NN'), ('and', 'CC'), ('sports.', 'NN')]\n",
            "\n",
            "6 [('Home', 'NN'), ('to', 'TO'), ('the', 'DT'), ('headquarters', 'NN'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('Nations,', 'NNP'), ('New', 'NNP'), ('York', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('important', 'JJ'), ('center', 'NN'), ('for', 'IN'), ('international', 'JJ'), ('diplomacy.Situated', 'NN'), ('on', 'IN'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), (\"world's\", 'NNS'), ('largest', 'JJS'), ('natural', 'JJ'), ('harbors,', 'NN'), ('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('is', 'VBZ'), ('divided', 'VBN'), ('into', 'IN'), ('five', 'CD'), ('administrative', 'JJ'), ('boroughs,', 'NN'), ('each', 'DT'), ('of', 'IN'), ('which', 'WDT'), ('is', 'VBZ'), ('a', 'DT'), ('separate', 'JJ'), ('county', 'NN'), ('of', 'IN'), ('the', 'DT'), ('State', 'NNP'), ('of', 'IN'), ('New', 'NNP'), ('York.', 'NNP')]\n",
            "\n",
            "7 [('The', 'DT'), ('five', 'CD'), ('boroughs', 'NNS'), ('–', 'NNP'), ('Brooklyn,', 'NNP'), ('Queens,', 'NNP'), ('Manhattan,', 'NNP'), ('The', 'NNP'), ('Bronx,', 'NNP'), ('and', 'CC'), ('Staten', 'NNP'), ('Island', 'NNP'), ('–', 'NNP'), ('were', 'VBD'), ('consolidated', 'VBN'), ('into', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('city', 'NN'), ('in', 'FW'), ('1898.', 'FW')]\n",
            "\n",
            "8 [('The', 'DT'), ('city', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('metropolitan', 'JJ'), ('area', 'NN'), ('constitute', 'VBP'), ('the', 'DT'), ('premier', 'JJ'), ('gateway', 'NN'), ('for', 'IN'), ('legal', 'JJ'), ('immigration', 'NN'), ('to', 'TO'), ('the', 'DT'), ('United', 'NNP'), ('States.', 'NNP')]\n",
            "\n",
            "9 [('As', 'RB'), ('many', 'JJ'), ('as', 'IN'), ('800', 'CD'), ('languages', 'NNS'), ('are', 'VBP'), ('spoken', 'VBN'), ('in', 'IN'), ('New', 'NNP'), ('York,', 'NNP'), ('making', 'VBG'), ('it', 'PRP'), ('the', 'DT'), ('most', 'RBS'), ('linguistically', 'RB'), ('diverse', 'JJ'), ('city', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world.', 'NN')]\n",
            "\n",
            "10 [('New', 'NNP'), ('York', 'NNP'), ('is', 'VBZ'), ('home', 'NN'), ('to', 'TO'), ('3.2', 'CD'), ('million', 'CD'), ('residents', 'NNS'), ('born', 'VBN'), ('outside', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States,', 'NNP'), ('the', 'DT'), ('largest', 'JJS'), ('foreign-born', 'JJ'), ('population', 'NN'), ('of', 'IN'), ('any', 'DT'), ('city', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('as', 'IN'), ('of', 'IN'), ('2016.', 'CD')]\n",
            "\n",
            "11 [('As', 'IN'), ('of', 'IN'), ('2019,', 'CD'), ('the', 'DT'), ('New', 'NNP'), ('York', 'NNP'), ('metropolitan', 'JJ'), ('area', 'NN'), ('is', 'VBZ'), ('estimated', 'VBN'), ('to', 'TO'), ('produce', 'VB'), ('a', 'DT'), ('gross', 'JJ'), ('metropolitan', 'JJ'), ('product', 'NN'), ('(GMP)', 'NN'), ('of', 'IN'), ('$2.0', 'FW'), ('trillion.', 'FW')]\n",
            "\n",
            "12 [('If', 'IN'), ('greater', 'JJR'), ('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('were', 'VBD'), ('a', 'DT'), ('sovereign', 'JJ'), ('state,', 'NN'), ('it', 'PRP'), ('would', 'MD'), ('have', 'VB'), ('the', 'DT'), ('12th', 'JJ'), ('highest', 'JJS'), ('GDP', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world.', 'NN')]\n",
            "\n",
            "13 [('New', 'NNP'), ('York', 'NNP'), ('is', 'VBZ'), ('home', 'NN'), ('to', 'TO'), ('the', 'DT'), ('highest', 'JJS'), ('number', 'NN'), ('of', 'IN'), ('billionaires', 'NNS'), ('of', 'IN'), ('any', 'DT'), ('city', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world.', 'NN')]\n",
            "\n",
            "14 [('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('traces', 'NNS'), ('its', 'PRP$'), ('origins', 'NNS'), ('to', 'TO'), ('a', 'DT'), ('trading', 'NN'), ('post', 'NN'), ('founded', 'VBN'), ('by', 'IN'), ('colonists', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('Dutch', 'NNP'), ('Republic', 'NNP'), ('in', 'IN'), ('1624', 'CD'), ('on', 'IN'), ('Lower', 'NNP'), ('Manhattan;', 'NNP'), ('the', 'DT'), ('post', 'NN'), ('was', 'VBD'), ('named', 'VBN'), ('New', 'NNP'), ('Amsterdam', 'NNP'), ('in', 'FW'), ('1626.', 'FW')]\n",
            "\n",
            "15 [('The', 'DT'), ('city', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('surroundings', 'NNS'), ('came', 'VBD'), ('under', 'IN'), ('English', 'JJ'), ('control', 'NN'), ('in', 'IN'), ('1664', 'CD'), ('and', 'CC'), ('were', 'VBD'), ('renamed', 'VBN'), ('New', 'NNP'), ('York', 'NNP'), ('after', 'IN'), ('King', 'NNP'), ('Charles', 'NNP'), ('II', 'NNP'), ('of', 'IN'), ('England', 'NNP'), ('granted', 'VBD'), ('the', 'DT'), ('lands', 'NNS'), ('to', 'TO'), ('his', 'PRP$'), ('brother,', 'NN'), ('the', 'DT'), ('Duke', 'NNP'), ('of', 'IN'), ('York.', 'NNP')]\n",
            "\n",
            "16 [('New', 'NNP'), ('York', 'NNP'), ('was', 'VBD'), ('the', 'DT'), ('capital', 'NN'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('from', 'IN'), ('1785', 'CD'), ('until', 'IN'), ('1790,', 'CD'), ('and', 'CC'), ('has', 'VBZ'), ('been', 'VBN'), ('the', 'DT'), ('largest', 'JJS'), ('U.S.', 'NNP'), ('city', 'NN'), ('since', 'IN'), ('1790.', 'CD')]\n",
            "\n",
            "17 [('The', 'DT'), ('Statue', 'NNP'), ('of', 'IN'), ('Liberty', 'NNP'), ('greeted', 'VBD'), ('millions', 'NNS'), ('of', 'IN'), ('immigrants', 'NNS'), ('as', 'IN'), ('they', 'PRP'), ('came', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('U.S.', 'NNP'), ('by', 'IN'), ('ship', 'NN'), ('in', 'IN'), ('the', 'DT'), ('late', 'JJ'), ('19th', 'JJ'), ('and', 'CC'), ('early', 'JJ'), ('20th', 'JJ'), ('centuries', 'NNS'), ('and', 'CC'), ('is', 'VBZ'), ('a', 'DT'), ('symbol', 'NN'), ('of', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('and', 'CC'), ('its', 'PRP$'), ('ideals', 'NNS'), ('of', 'IN'), ('liberty', 'NN'), ('and', 'CC'), ('peace.', 'NN')]\n",
            "\n",
            "18 [('In', 'IN'), ('the', 'DT'), ('21st', 'JJ'), ('century,', 'NN'), ('New', 'NNP'), ('York', 'NNP'), ('has', 'VBZ'), ('emerged', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('global', 'JJ'), ('node', 'NN'), ('of', 'IN'), ('creativity', 'NN'), ('and', 'CC'), ('entrepreneurship', 'NN'), ('and', 'CC'), ('environmental', 'JJ'), ('sustainability,', 'NN'), ('and', 'CC'), ('as', 'IN'), ('a', 'DT'), ('symbol', 'NN'), ('of', 'IN'), ('freedom', 'NN'), ('and', 'CC'), ('cultural', 'JJ'), ('diversity.', 'NN')]\n",
            "\n",
            "19 [('In', 'IN'), ('2019,', 'NNP'), ('New', 'NNP'), ('York', 'NNP'), ('was', 'VBD'), ('voted', 'VBN'), ('the', 'DT'), ('greatest', 'JJS'), ('city', 'NN'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('per', 'IN'), ('a', 'DT'), ('survey', 'NN'), ('of', 'IN'), ('over', 'IN'), ('30,000', 'CD'), ('people', 'NNS'), ('from', 'IN'), ('48', 'CD'), ('cities', 'NNS'), ('worldwide,', 'NN'), ('citing', 'VBG'), ('its', 'PRP$'), ('cultural', 'JJ'), ('diversity.Many', 'NN'), ('districts', 'NNS'), ('and', 'CC'), ('landmarks', 'NNS'), ('in', 'IN'), ('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('are', 'VBP'), ('well', 'RB'), ('known,', 'JJ'), ('including', 'VBG'), ('three', 'CD'), ('of', 'IN'), ('the', 'DT'), (\"world's\", 'NN'), ('ten', 'CD'), ('most', 'RBS'), ('visited', 'VBN'), ('tourist', 'NN'), ('attractions', 'NNS'), ('in', 'IN'), ('2013.', 'NN')]\n",
            "\n",
            "20 [('A', 'DT'), ('record', 'JJ'), ('62.8', 'CD'), ('million', 'CD'), ('tourists', 'NNS'), ('visited', 'VBD'), ('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP'), ('in', 'FW'), ('2017.', 'FW')]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIdQShPdS0Dp",
        "colab_type": "text"
      },
      "source": [
        "# Exercitiul 1.2\n",
        "If I would use the single_pos_to_words() function in order to construct the multi_pos_to_words() function it would parse the same article multiple times looking individually for each pos as it does in the single_pos_to_words()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-EIi3sCmnVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article = wikipedia.page('New York City')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-wYYKYYQTQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_pos_to_words(pos, article):\n",
        "  #pos -  needs to be a single pos\n",
        "  #article - needs to be an wikipedia.page('title') object\n",
        "  all_sentences = sent_tokenize(article.content)[:20]\n",
        "  buffer_array = []\n",
        "  for sentence in all_sentences:\n",
        "    pos_list = tagger.tag(sentence.split())\n",
        "    for item in pos_list:    \n",
        "      if item[1]==pos:\n",
        "        buffer_array.append(item[0])\n",
        "  return buffer_array\n",
        "\n",
        "def multi_pos_to_words(pos, article):\n",
        "  #pos -  needs to be an array of pos taggs\n",
        "  #article - needs to be an wikipedia.page('title') object\n",
        "  all_sentences = sent_tokenize(article.content)[:20]\n",
        "  buffer_array = []\n",
        "  for sentence in all_sentences:\n",
        "    pos_list = tagger.tag(sentence.split())\n",
        "    for item in pos_list:    \n",
        "      for pos_item in pos:\n",
        "        if item[1]==pos_item:\n",
        "          buffer_array.append(item[0])\n",
        "  return buffer_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ5RTUGEUjy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_New_York_City = []\n",
        "nn_New_York_City.append(multi_pos_to_words(['NN'],article))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CuiP9YyUjwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04088369-579e-4fdb-e43b-a7031cc7f159"
      },
      "source": [
        "print(len(nn_New_York_City[0]))\n",
        "print(nn_New_York_City[0][:10])"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76\n",
            "['city', 'population', 'city', 'tip', 'state', 'city', 'center', 'area,', 'area', 'world']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCHARxv6kxkQ",
        "colab_type": "text"
      },
      "source": [
        "# Exercitiul 1.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeWD2AwnUjq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_New_York_City = []\n",
        "pos_New_York_City.append(multi_pos_to_words(['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ'],article))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2RqSY57Ujn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9226800c-24b1-4f1c-fab7-72462f238ba5"
      },
      "source": [
        "list_of_words = word_tokenize(article.content)\n",
        "print(\"All the words:\",len(list_of_words))\n",
        "print(\"All the nouns+verbs:\",np.shape(pos_New_York_City)[1])\n",
        "percentage = np.round(np.shape(pos_New_York_City)[1] / len(list_of_words) * 100, 2)\n",
        "print(\"Percetange of nouns+verbs from total words:\",str(percentage)+'%')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All the words: 21545\n",
            "All the nouns+verbs: 247\n",
            "Percetange of nouns+verbs from total words: 1.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS05B0_lwEuY",
        "colab_type": "text"
      },
      "source": [
        "# Exercitiul 1.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbPTEcI3vd1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYkDqWjYvd9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_col = 'Original word'\n",
        "second_col = 'POS '\n",
        "third_col = 'Simple lemmatization'\n",
        "fourth_col = 'Lemmatization with POS'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cipsVtgKvd4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_col_list = []\n",
        "second_col_list = []\n",
        "third_col_list = []\n",
        "fourth_col_list = []\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "# contor_s = 0\n",
        "for sentence in first200s[:30]:\n",
        "  # contor_s += 1; print(\"Sentence:\",str(contor_s)+'/'+str(len(first200s[:10])))\n",
        "  # contor_w = 1\n",
        "  for word in tokenizer.tokenize(sentence):\n",
        "    # x = \"Word: \"+str(contor_w)+'/'+str(len(tokenizer.tokenize(sentence)))\n",
        "    # contor_w += 1; print(x)\n",
        "  # for word in sentence.split():\n",
        "    # print(\"================\")\n",
        "    first_col_list.append(word)\n",
        "    # print(word)\n",
        "    pos = tagger.tag([word])\n",
        "    second_col_list.append(pos)\n",
        "    # print(pos)\n",
        "    third_col_list.append(lem.lemmatize(word))\n",
        "    # print(lem.lemmatize(word))\n",
        "    fourth_col_list.append(lem.lemmatize(word, pos=get_wordnet_pos(\"running\")))\n",
        "    # print(lem.lemmatize(word, pos=get_wordnet_pos(\"running\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRkXJR1_JdUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "33f65d9d-64be-45b4-b67d-cbd5acfecfc9"
      },
      "source": [
        "first_unique, first_unique_index = np.unique(first_col_list, return_index=True)\n",
        "first_unique_index"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([301, 509, 669, 316, 356, 367, 378, 410, 412, 216, 443, 260,  93,\n",
              "       542, 281, 554,  28, 284, 446, 465, 103, 634, 259, 508,  37,  32,\n",
              "       662, 512,  38, 545, 635,  33,  41,  31, 237, 543, 801, 803, 365,\n",
              "       234, 624, 564, 205, 201, 386, 628, 620,   2, 674, 566, 397, 353,\n",
              "       784, 389, 375, 729, 710, 717, 318, 298, 728, 149, 387, 303, 463,\n",
              "       208, 747, 385, 806, 426,  57, 358, 203, 519, 726, 723,  15,   3,\n",
              "       156, 802, 769, 645,   0, 632, 202, 354, 680,  65, 166, 646, 556,\n",
              "       194, 207,  24, 424, 709, 714, 651, 198, 565, 555,  64,  23, 675,\n",
              "       713,  25,   1, 189,  36, 629, 183, 384,  92,  46, 605,  26, 101,\n",
              "       274, 759, 102, 239,  80, 596, 145, 126,  58, 540, 745, 124, 331,\n",
              "       263, 184, 559, 395, 572,  88,   5, 373, 132, 704,  74, 447, 466,\n",
              "       513, 515,  20, 670, 350, 107, 138, 210, 223, 633, 638, 376, 191,\n",
              "       476, 128, 794,  49, 125, 165, 627,  34, 520, 249, 490, 180, 185,\n",
              "       445, 142, 470, 139, 478, 480, 789, 602,  27, 619, 700, 608, 146,\n",
              "       129, 182, 163, 270, 765, 348, 487, 351, 226, 473, 390, 304, 498,\n",
              "       427, 295, 758, 175, 123, 314, 724, 152, 317, 394, 785, 257, 737,\n",
              "       561, 458, 560, 430, 229, 161,  21, 530, 584, 137, 799, 164, 574,\n",
              "       181,  16, 110,  97,  42, 529, 522,  90, 392, 238,  82, 442, 228,\n",
              "       460, 248, 711,  51, 244, 235, 603, 131, 119,  79,  40,  94, 428,\n",
              "        18, 626, 363, 705, 174, 641, 474, 329,   8,   4, 753, 167, 112,\n",
              "       656,  11, 343, 264,  35, 593, 462, 573,  95, 503, 143,  50,  29,\n",
              "        19, 347, 788, 225, 793, 293, 297, 762, 663, 682, 657, 601, 779,\n",
              "       544, 381, 140, 262, 116, 780, 190, 636, 439, 136,  12, 421, 213,\n",
              "       591,  60, 310, 240, 148,  39,  66, 664,  99, 699, 372, 505, 481,\n",
              "       451, 659, 141, 536, 766, 644,   6, 432, 531,  61, 150, 685, 702,\n",
              "       144, 539, 548, 341, 346, 658, 302, 697, 374, 672, 411,  89, 538,\n",
              "       496, 362, 528, 209, 187, 743, 625,  87, 514, 313])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkf_XemN-i3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bf2b82f-1e33-492e-a1b1-8a1f1c3debe3"
      },
      "source": [
        "second_col_list_ex15 = []\n",
        "print(\"First 30 sentences\")\n",
        "print(first_col + \" | \" + second_col + \" | \" + third_col + \" | \" + fourth_col)\n",
        "print('--------------------------------------------------------------------')\n",
        "for index in first_unique_index:\n",
        "  if (third_col_list[index] != fourth_col_list[index]):\n",
        "\n",
        "    first_dif = len(first_col) - len(first_col_list[index])\n",
        "    first_spaces = \"\"\n",
        "    for i in range(first_dif):\n",
        "      first_spaces = first_spaces + \" \"\n",
        "    \n",
        "    second_dif = len(second_col) - len(second_col_list[index][0][1][:3])\n",
        "    second_spaces = \"\"\n",
        "    for i in range(second_dif):\n",
        "      second_spaces = second_spaces + \" \"\n",
        "\n",
        "    third_dif = len(third_col) - len(third_col_list[index])\n",
        "    third_spaces = \"\"\n",
        "    for i in range(third_dif):\n",
        "      third_spaces = third_spaces + \" \"\n",
        "    \n",
        "    fourth_dif = len(fourth_col) - len(fourth_col_list[index])\n",
        "    fourth_spaces = \"\"\n",
        "    for i in range(fourth_dif):\n",
        "      fourth_spaces = fourth_spaces + \" \"\n",
        "\n",
        "    second_col_list_ex15.append(second_col_list[index][0][1][:3])\n",
        "    print(first_col_list[index]+first_spaces + \" | \"+ second_col_list[index][0][1][:3]+second_spaces + \" | \" + third_col_list[index]+third_spaces + \" | \" + fourth_col_list[index])"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 30 sentences\n",
            "Original word | POS  | Simple lemmatization | Lemmatization with POS\n",
            "--------------------------------------------------------------------\n",
            "appointed     | VBN  | appointed            | appoint\n",
            "are           | VBP  | are                  | be\n",
            "as            | IN   | a                    | as\n",
            "attractions   | NNS  | attraction           | attractions\n",
            "been          | VBN  | been                 | be\n",
            "billionaires  | NNS  | billionaire          | billionaires\n",
            "born          | VBN  | born                 | bear\n",
            "boroughs      | NNS  | borough              | boroughs\n",
            "called        | VBN  | called               | call\n",
            "came          | VBD  | came                 | come\n",
            "centuries     | NNS  | century              | centuries\n",
            "cities        | NNS  | city                 | cities\n",
            "citing        | VBG  | citing               | cite\n",
            "colleges      | NNS  | college              | colleges\n",
            "colonists     | NNS  | colonist             | colonists\n",
            "combined      | VBN  | combined             | combine\n",
            "consolidated  | VBN  | consolidated         | consolidate\n",
            "contributing  | VBG  | contributing         | contribute\n",
            "described     | VBN  | described            | describe\n",
            "distributed   | VBN  | distributed          | distribute\n",
            "divided       | VBN  | divided              | divide\n",
            "emerged       | VBD  | emerged              | emerge\n",
            "estimated     | VBN  | estimated            | estimate\n",
            "founded       | VBN  | founded              | found\n",
            "granted       | VBN  | granted              | grant\n",
            "greeted       | VBN  | greeted              | greet\n",
            "had           | VBD  | had                  | have\n",
            "has           | VBZ  | ha                   | have\n",
            "headquartered | VBN  | headquartered        | headquarter\n",
            "headquarters  | NNS  | headquarters         | headquarter\n",
            "ideals        | NNS  | ideal                | ideals\n",
            "illuminated   | VBN  | illuminated          | illuminate\n",
            "immigrants    | NNS  | immigrant            | immigrants\n",
            "including     | VBG  | including            | include\n",
            "influencing   | VBG  | influencing          | influence\n",
            "inhabited     | VBN  | inhabited            | inhabit\n",
            "intersections | NNS  | intersection         | intersections\n",
            "is            | VBZ  | is                   | be\n",
            "its           | PRP  | it                   | its\n",
            "known         | VBN  | known                | know\n",
            "landmarks     | NNS  | landmark             | landmarks\n",
            "languages     | NNS  | language             | languages\n",
            "located       | JJ   | located              | locate\n",
            "making        | VBG  | making               | make\n",
            "media         | NNS  | medium               | media\n",
            "miles         | NNS  | mile                 | miles\n",
            "millions      | NNS  | million              | millions\n",
            "named         | VBN  | named                | name\n",
            "origins       | NNS  | origin               | origins\n",
            "populated     | VBN  | populated            | populate\n",
            "ranked        | VBN  | ranked               | rank\n",
            "renamed       | VBN  | renamed              | rename\n",
            "residents     | NNS  | resident             | residents\n",
            "seized        | VBN  | seized               | seize\n",
            "skyscrapers   | NNS  | skyscraper           | skyscrapers\n",
            "spoken        | VBN  | spoken               | speak\n",
            "surroundings  | NNS  | surroundings         | surround\n",
            "tourists      | NNS  | tourist              | tourists\n",
            "trading       | NN   | trading              | trade\n",
            "universities  | NNS  | university           | universities\n",
            "visited       | VBN  | visited              | visit\n",
            "voted         | VBD  | voted                | vote\n",
            "was           | VBD  | wa                   | be\n",
            "were          | VBD  | were                 | be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiey10mLC2c3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "9da4eade-60f3-4e15-d4a8-bddc381ae9f8"
      },
      "source": [
        "count = Counter(second_col_list_ex15)\n",
        "df = pandas.DataFrame.from_dict(count, orient='index')\n",
        "df.plot(kind='bar')"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x12910d590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlVnB8SUC2aT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeykcEmHC2Ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGijFcP7-i0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9hXzgRe6OGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2a249b75-6756-448b-95df-f1742bad2dee"
      },
      "source": [
        "# function to get unique values \n",
        "def unique(list1): \n",
        "    x = np.array(list1) \n",
        "    print(np.unique(x, return_index=True)) \n",
        "      \n",
        "  \n",
        "# driver code \n",
        "list1 = [10, 20, 10, 30, 40, 40] \n",
        "print(\"the unique values from 1st list is\") \n",
        "unique(list1) \n",
        "  \n",
        "  \n",
        "list2 =[1, 2, 1, 1, 3, 4, 3, 3, 5] \n",
        "print(\"\\nthe unique values from 2nd list is\") \n",
        "unique(list2) "
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the unique values from 1st list is\n",
            "(array([10, 20, 30, 40]), array([0, 1, 3, 4]))\n",
            "\n",
            "the unique values from 2nd list is\n",
            "(array([1, 2, 3, 4, 5]), array([0, 1, 4, 5, 8]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7uns7Bc6OEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-2KM7c06OBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaYXr6mw6N8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}